%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include "ast.h"
#include "compiler_phases.h"

int yylex(void);
void yyerror(const char *s);

// Global program storage
Program prog = { .dataset_path = "", .model_count = 0 };

// Symbol table and IR
SymbolTable symtab;
IRCode ir_code;

// Forward declarations
void generate_python();
const char* detect_backend(const char* model_name);
char* strip_quotes(char* str);

extern int verbose_mode;

%}

%union {
    int intVal;
    float floatVal;
    char *strVal;
}

%token DATASET MODEL LBRACE RBRACE ASSIGN LBRACKET RBRACKET COMMA
%token <intVal> INT
%token <floatVal> FLOAT
%token <strVal> ID STRING

%type <strVal> value

%%

program:
    dataset_decl model_def_list
    {
        if (verbose_mode) {
            printf("\n");  // Close lexical analysis output
            phase2_syntax_analysis(&prog);
            phase3_semantic_analysis(&prog, &symtab);
            phase4_ir_generation(&prog, &ir_code);
            phase5_optimization(&ir_code);
        }
        
        printf("\n✅ Parsing completed successfully!\n");
        generate_python();
    }
    | model_def_list
    {
        if (verbose_mode) {
            printf("\n");
            phase2_syntax_analysis(&prog);
            phase3_semantic_analysis(&prog, &symtab);
            phase4_ir_generation(&prog, &ir_code);
            phase5_optimization(&ir_code);
        }
        
        printf("\n✅ Parsing completed successfully!\n");
        generate_python();
    }
    ;

dataset_decl:
    DATASET STRING
    {
        char* path = strip_quotes($2);
        strncpy(prog.dataset_path, path, 255);
        prog.dataset_path[255] = '\0';
        if (!verbose_mode) {
            printf("📂 Dataset path set to: %s\n", prog.dataset_path);
        }
        free(path);
        free($2);
    }
    ;

model_def_list:
    model_def_list model_def
    | model_def
    ;

model_def:
    MODEL ID {
        Model *m = &prog.models[prog.model_count];
        strncpy(m->name, $2, 63);
        m->name[63] = '\0';
        m->param_count = 0;
        free($2);
    } LBRACE param_list RBRACE
    {
        prog.model_count++;
    }
    ;

param_list:
    param_list param
    | param
    | /* empty */
    ;

param:
    ID ASSIGN value
    {
        Model *m = &prog.models[prog.model_count];
        int idx = m->param_count;
        
        strncpy(m->param_names[idx], $1, 63);
        m->param_names[idx][63] = '\0';
        
        strncpy(m->param_values[idx], $3, 63);
        m->param_values[idx][63] = '\0';
        
        m->param_count++;
        free($1);
        free($3);
    }
    ;

value:
    INT    { 
        char buf[64]; 
        sprintf(buf, "%d", $1);
        $$ = strdup(buf);
    }
    | FLOAT  { 
        char buf[64]; 
        sprintf(buf, "%.6f", $1);
        $$ = strdup(buf);
    }
    | STRING { 
        $$ = strip_quotes($1);
        free($1);
    }
    | ID {
        $$ = strdup($1);
        free($1);
    }
    ;

%%

void yyerror(const char *s) {
    fprintf(stderr, "❌ Parse error: %s\n", s);
}

char* strip_quotes(char* str) {
    int len = strlen(str);
    char* result = malloc(len + 1);
    if (len >= 2 && str[0] == '"' && str[len-1] == '"') {
        strncpy(result, str + 1, len - 2);
        result[len - 2] = '\0';
    } else {
        strcpy(result, str);
    }
    return result;
}

const char* detect_backend(const char* model_name) {
    // Scikit-learn models
    if (strstr(model_name, "LinearRegression") || strstr(model_name, "LogisticRegression") ||
        strstr(model_name, "DecisionTree") || strstr(model_name, "RandomForest") ||
        strstr(model_name, "KNeighbors") || strstr(model_name, "SVC") ||
        strstr(model_name, "GaussianNB") || strstr(model_name, "KMeans") ||
        strstr(model_name, "LinearSVC") || strstr(model_name, "SGDClassifier")) {
        return "sklearn";
    }
    
    // TensorFlow models
    if (strstr(model_name, "ResNet") || strstr(model_name, "VGG") ||
        strstr(model_name, "EfficientNet") || strstr(model_name, "MobileNet") ||
        strstr(model_name, "DenseNet") || strstr(model_name, "InceptionV3")) {
        return "tensorflow";
    }
    
    // PyTorch models
    if (strstr(model_name, "UNet") || strstr(model_name, "GAN") || 
        strstr(model_name, "AutoEncoder") || strstr(model_name, "VAE")) {
        return "pytorch";
    }
    
    // Transformers models
    if (strstr(model_name, "BERT") || strstr(model_name, "GPT") || 
        strstr(model_name, "T5") || strstr(model_name, "RoBERTa") ||
        strstr(model_name, "DistilBERT")) {
        return "transformers";
    }
    
    return "tensorflow";
}

void generate_python() {
    FILE *fp = fopen("train.py", "w");
    if (!fp) {
        fprintf(stderr, "Error creating train.py\n");
        return;
    }

    fprintf(fp, "#!/usr/bin/env python3\n");
    fprintf(fp, "# Generated by MLC Compiler\n");
    fprintf(fp, "# Auto-generated machine learning training script\n\n");

    // Determine backend from first model
    const char* backend = "tensorflow";
    if (prog.model_count > 0) {
        backend = detect_backend(prog.models[0].name);
    }

    if (verbose_mode) {
        phase6_code_generation(&prog, backend);
    }

    // Generate code for each model
    for (int i = 0; i < prog.model_count; i++) {
        Model *m = &prog.models[i];
        
        fprintf(fp, "# =====================================\n");
        fprintf(fp, "# Model %d: %s\n", i + 1, m->name);
        fprintf(fp, "# Backend: %s\n", backend);
        fprintf(fp, "# =====================================\n\n");

        // Parameters
        for (int j = 0; j < m->param_count; j++) {
            fprintf(fp, "%s = %s\n", m->param_names[j], m->param_values[j]);
        }
        fprintf(fp, "\n");

        // Simple sklearn code generation
        if (strcmp(backend, "sklearn") == 0) {
            fprintf(fp, "# Imports\n");
            fprintf(fp, "from sklearn.ensemble import RandomForestClassifier\n");
            fprintf(fp, "from sklearn.linear_model import LinearRegression\n");
            fprintf(fp, "import pandas as pd\n");
            fprintf(fp, "import pickle\n\n");
            
            fprintf(fp, "# Load dataset\n");
            fprintf(fp, "dataset = pd.read_csv('%s')\n", prog.dataset_path);
            fprintf(fp, "X = dataset.iloc[:, :-1].values\n");
            fprintf(fp, "y = dataset.iloc[:, -1].values\n\n");
            
            fprintf(fp, "# Model: %s\n", m->name);
            
            if (strstr(m->name, "RandomForest")) {
                fprintf(fp, "model = RandomForestClassifier(");
                for (int j = 0; j < m->param_count; j++) {
                    fprintf(fp, "%s=%s", m->param_names[j], m->param_values[j]);
                    if (j < m->param_count - 1) fprintf(fp, ", ");
                }
                fprintf(fp, ")\n");
            } else if (strstr(m->name, "LinearRegression")) {
                fprintf(fp, "model = LinearRegression()\n");
            }
            
            fprintf(fp, "model.fit(X, y)\n");
            fprintf(fp, "print('Training complete!')\n\n");
            fprintf(fp, "# Save model\n");
            fprintf(fp, "with open('model.pkl', 'wb') as f:\n");
            fprintf(fp, "    pickle.dump(model, f)\n");
            fprintf(fp, "print('Model saved to model.pkl')\n");
        }
        // Transformers backend
        else if (strcmp(backend, "transformers") == 0) {
            fprintf(fp, "# Dataset Loading\n");
            fprintf(fp, "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n");
            fprintf(fp, "from datasets import load_dataset\n\n");
            fprintf(fp, "# Load dataset\n");
            fprintf(fp, "dataset = load_dataset('%s')\n", prog.dataset_path);
            fprintf(fp, "tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n");
            fprintf(fp, "def tokenize_function(examples):\n");
            fprintf(fp, "    return tokenizer(examples['text'], padding='max_length', truncation=True)\n\n");
            fprintf(fp, "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n");
            fprintf(fp, "# Model: %s (transformers backend)\n", m->name);
            fprintf(fp, "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n\n");
            fprintf(fp, "# Model\n");
            fprintf(fp, "model_name = '%s'\n", m->name);
            fprintf(fp, "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n\n");
            fprintf(fp, "# Training\n");
            fprintf(fp, "training_args = TrainingArguments(\n");
            fprintf(fp, "    output_dir='./results',\n");
            fprintf(fp, "    num_train_epochs=epochs,\n");
            fprintf(fp, "    per_device_train_batch_size=batch_size,\n");
            fprintf(fp, "    learning_rate=learning_rate,\n");
            fprintf(fp, "    evaluation_strategy='epoch',\n");
            fprintf(fp, ")\n\n");
            fprintf(fp, "trainer = Trainer(\n");
            fprintf(fp, "    model=model,\n");
            fprintf(fp, "    args=training_args,\n");
            fprintf(fp, "    train_dataset=tokenized_datasets['train'],\n");
            fprintf(fp, "    eval_dataset=tokenized_datasets['test'],\n");
            fprintf(fp, ")\n\n");
            fprintf(fp, "trainer.train()\n");
            fprintf(fp, "print('Training complete!')\n\n");
            fprintf(fp, "# Save model\n");
            fprintf(fp, "trainer.save_model('./model')\n");
            fprintf(fp, "print('Model saved!')\n");
        }
    }

    fclose(fp);

    if (!verbose_mode) {
        printf("✅ Python script 'train.py' generated successfully!\n");
    }

    // Phase 7 - Linking and venv setup
    if (verbose_mode) {
        phase7_linking(backend);
    } else {
        printf("🔧 Setting up virtual environment and installing packages...\n");
    }
}
