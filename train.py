#!/usr/bin/env python3
# Generated by MLC Compiler
# Auto-generated machine learning training script

# =====================================
# Model 1: ResNet50
# Backend: tensorflow
# =====================================

epochs = 10
batch_size = 32
learning_rate = 0.001000

# Dataset Loading
import tensorflow as tf

# Load dataset from directory
train_ds = tf.keras.utils.image_dataset_from_directory(
    '/home/madhava/datasets/flowers',
    image_size=(224, 224),
    batch_size=batch_size,
    label_mode='categorical'
)

# Normalize pixel values
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))

# Model: ResNet50 (tensorflow backend)
import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model

# Build model
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(len(train_ds.class_names), activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# Compile model
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Training
print('ðŸš€ Starting training...')
history = model.fit(
    train_ds,
    epochs=epochs,
    verbose=1
)

print('âœ… Training completed!')
model.save('trained_model.h5')
print('ðŸ’¾ Model saved as trained_model.h5')

